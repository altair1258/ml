{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insurance Claim Prediction - Clean Pipeline\n",
    "Complete ML pipeline with proper train/test split handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import math\n",
    "\n",
    "print(\"Libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"train_Insurance.csv\")\n",
    "test_raw = pd.read_csv(\"test_Insurance.csv\")\n",
    "\n",
    "print(f\"Train shape: {train_raw.shape}\")\n",
    "print(f\"Test shape: {test_raw.shape}\")\n",
    "print(f\"\\nTrain columns: {list(train_raw.columns)}\")\n",
    "print(f\"\\nTrain missing values:\\n{train_raw.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning Pipeline (Train Only for Fitting)\n",
    "\n",
    "### Step 1: Remove Customer ID from both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw.drop(labels=['Customer Id'], axis=1, inplace=True)\n",
    "test_raw.drop(labels=['Customer Id'], axis=1, inplace=True)\n",
    "\n",
    "print(f\"Columns after removing Customer ID: {list(train_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Clean NumberOfWindows (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw['NumberOfWindows'] = train_raw['NumberOfWindows'].replace({'without': 0, '>=10': 10})\n",
    "train_raw['NumberOfWindows'] = train_raw['NumberOfWindows'].astype(int)\n",
    "\n",
    "test_raw['NumberOfWindows'] = test_raw['NumberOfWindows'].replace({'without': 0, '>=10': 10})\n",
    "test_raw['NumberOfWindows'] = test_raw['NumberOfWindows'].astype(int)\n",
    "\n",
    "print(\"NumberOfWindows cleaned in both datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Remove Duplicates and Conflicts (Train Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_exact = train_raw.duplicated().sum()\n",
    "n_same_features = train_raw.duplicated(subset=[c for c in train_raw.columns if c != 'Claim']).sum()\n",
    "\n",
    "print(f\"Exact duplicates: {n_exact}\")\n",
    "print(f\"Duplicates with same features: {n_same_features}\")\n",
    "\n",
    "if n_same_features > 0:\n",
    "    features = [c for c in train_raw.columns if c != \"Claim\"]\n",
    "    dups = train_raw[train_raw.duplicated(subset=features, keep=False)]\n",
    "    conflicts = dups.groupby(features)['Claim'].nunique()\n",
    "    n_conflicts = (conflicts > 1).sum()\n",
    "    print(f\"Conflicting records: {n_conflicts}\")\n",
    "    \n",
    "    if n_conflicts > 0:\n",
    "        conflicting_groups = conflicts[conflicts > 1].reset_index()\n",
    "        before = len(train_raw)\n",
    "        train_raw = train_raw.merge(conflicting_groups[features], on=features, how='left', indicator=True)\n",
    "        train_raw = train_raw[train_raw['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "        after = len(train_raw)\n",
    "        print(f\"Removed {before - after} conflicting records\")\n",
    "\n",
    "train_raw.drop_duplicates(inplace=True)\n",
    "print(f\"Train shape after cleaning: {train_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Handle Missing Values in Train (fit imputers here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values in train:\")\n",
    "print(train_raw.isna().sum())\n",
    "\n",
    "mf_imputer = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "train_raw[[\"Garden\"]] = mf_imputer.fit_transform(train_raw[[\"Garden\"]])\n",
    "\n",
    "median_imputer = SimpleImputer(strategy=\"median\")\n",
    "train_raw[[\"Building Dimension\"]] = median_imputer.fit_transform(train_raw[[\"Building Dimension\"]])\n",
    "\n",
    "print(\"\\nImputers fitted on train data\")\n",
    "print(f\"Missing values after imputation:\\n{train_raw.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fill Missing Geo_Code using Train Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_geo_train = (\n",
    "    train_raw[train_raw[\"Geo_Code\"].notna()]\n",
    "    .groupby([\"Settlement\", \"Residential\"])[\"Geo_Code\"]\n",
    "    .agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Geo_Code\": \"Geo_Code_mode\"})\n",
    ")\n",
    "\n",
    "print(\"Train Geo_Code modes by Settlement+Residential:\")\n",
    "print(mode_geo_train)\n",
    "\n",
    "train_raw = train_raw.merge(mode_geo_train, on=[\"Settlement\", \"Residential\"], how=\"left\")\n",
    "train_raw[\"Geo_Code\"] = train_raw[\"Geo_Code\"].fillna(train_raw[\"Geo_Code_mode\"])\n",
    "train_raw = train_raw.drop(columns=[\"Geo_Code_mode\"])\n",
    "\n",
    "print(f\"\\nTrain missing values after Geo_Code fill: {train_raw['Geo_Code'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Clean Geo_Code (remove alphanumeric, convert to int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_numeric = train_raw[\"Geo_Code\"].astype(str).str.isnumeric()\n",
    "print(f\"Train numeric Geo_Code: {mask_numeric.sum()}\")\n",
    "print(f\"Train alphanumeric Geo_Code: {(~mask_numeric).sum()}\")\n",
    "\n",
    "train_raw = train_raw[mask_numeric].copy()\n",
    "train_raw[\"Geo_Code\"] = train_raw[\"Geo_Code\"].astype(int)\n",
    "\n",
    "print(f\"Train shape after Geo_Code cleaning: {train_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Handle Outliers in Building Dimension (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = train_raw['Building Dimension'].quantile(0.25)\n",
    "Q3 = train_raw['Building Dimension'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Building Dimension - Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
    "print(f\"Bounds: [{lower}, {upper}]\")\n",
    "\n",
    "outliers_before = (train_raw['Building Dimension'] < lower) | (train_raw['Building Dimension'] > upper)\n",
    "print(f\"Outliers found: {outliers_before.sum()}\")\n",
    "\n",
    "train_raw['Building Dimension'] = train_raw['Building Dimension'].clip(lower, upper)\n",
    "print(\"Outliers clipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Fit RobustScaler on Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scale = ['Building Dimension', 'NumberOfWindows']\n",
    "scaler = RobustScaler()\n",
    "\n",
    "train_raw[cols_to_scale] = scaler.fit_transform(train_raw[cols_to_scale])\n",
    "\n",
    "print(\"RobustScaler fitted and applied to train data\")\n",
    "print(f\"Scaled columns: {cols_to_scale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Encode Categorical Variables (Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformed = train_raw.copy()\n",
    "\n",
    "train_transformed[\"Building_Painted\"] = train_transformed[\"Building_Painted\"].map({'N': 1, 'V': 0}).astype('int32')\n",
    "train_transformed[\"Building_Fenced\"] = train_transformed[\"Building_Fenced\"].map({'N': 1, 'V': 0}).astype('int32')\n",
    "train_transformed[\"Garden\"] = train_transformed[\"Garden\"].map({'V': 1, 'O': 0}).astype('int32')\n",
    "\n",
    "train_transformed = pd.get_dummies(train_transformed, columns=[\"Settlement\", \"Building_Type\"], drop_first=True, dtype='int32')\n",
    "\n",
    "le_claim = LabelEncoder()\n",
    "train_transformed[\"Claim\"] = le_claim.fit_transform(train_transformed[\"Claim\"])\n",
    "\n",
    "cols = [c for c in train_transformed.columns if c != \"Claim\"] + [\"Claim\"]\n",
    "train_transformed = train_transformed[cols]\n",
    "\n",
    "print(\"Train data encoded\")\n",
    "print(f\"Train shape: {train_transformed.shape}\")\n",
    "print(f\"Train columns: {list(train_transformed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Drop Low Correlation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = train_transformed.corr(numeric_only=True)\n",
    "corr_with_claim = df_corr[[\"Claim\"]].sort_values(by=\"Claim\", ascending=False)\n",
    "\n",
    "print(\"Correlation with Claim:\")\n",
    "print(corr_with_claim)\n",
    "\n",
    "cols_to_drop = [\n",
    "    'Building_Painted',\n",
    "    'Geo_Code',\n",
    "    'YearOfObservation',\n",
    "    'Building_Type_Non-combustible'\n",
    "]\n",
    "\n",
    "train_transformed = train_transformed.drop(columns=cols_to_drop)\n",
    "train_transformed = train_transformed.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nFinal train shape: {train_transformed.shape}\")\n",
    "print(f\"Final train columns: {list(train_transformed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Same Transformations to Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Fill Missing Values Using Train-Fitted Imputers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test missing values before imputation:\")\n",
    "print(test_raw.isna().sum())\n",
    "\n",
    "test_raw[[\"Garden\"]] = mf_imputer.transform(test_raw[[\"Garden\"]])\n",
    "test_raw[[\"Building Dimension\"]] = median_imputer.transform(test_raw[[\"Building Dimension\"]])\n",
    "\n",
    "print(\"\\nTest data imputed using train-fitted imputers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Fill Missing Geo_Code Using Train Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = test_raw.merge(mode_geo_train, on=[\"Settlement\", \"Residential\"], how=\"left\")\n",
    "test_raw[\"Geo_Code\"] = test_raw[\"Geo_Code\"].fillna(test_raw[\"Geo_Code_mode\"])\n",
    "test_raw = test_raw.drop(columns=[\"Geo_Code_mode\"])\n",
    "\n",
    "print(f\"Test missing Geo_Code after fill: {test_raw['Geo_Code'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clean Geo_Code (same as train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_numeric_test = test_raw[\"Geo_Code\"].astype(str).str.isnumeric()\n",
    "print(f\"Test numeric Geo_Code: {mask_numeric_test.sum()}\")\n",
    "print(f\"Test alphanumeric Geo_Code: {(~mask_numeric_test).sum()}\")\n",
    "\n",
    "test_raw = test_raw[mask_numeric_test].copy()\n",
    "test_raw[\"Geo_Code\"] = test_raw[\"Geo_Code\"].astype(int)\n",
    "\n",
    "print(f\"Test shape after Geo_Code cleaning: {test_raw.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Apply Train Scaler (TRANSFORM only, not fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw[cols_to_scale] = scaler.transform(test_raw[cols_to_scale])\n",
    "\n",
    "print(\"Test data scaled using train-fitted scaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Encode Categorical Variables (Test) - Same as Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = test_raw.copy()\n",
    "\n",
    "test_transformed[\"Building_Painted\"] = test_transformed[\"Building_Painted\"].map({'N': 1, 'V': 0}).astype('int32')\n",
    "test_transformed[\"Building_Fenced\"] = test_transformed[\"Building_Fenced\"].map({'N': 1, 'V': 0}).astype('int32')\n",
    "test_transformed[\"Garden\"] = test_transformed[\"Garden\"].map({'V': 1, 'O': 0}).astype('int32')\n",
    "\n",
    "test_transformed = pd.get_dummies(test_transformed, columns=[\"Settlement\", \"Building_Type\"], drop_first=True, dtype='int32')\n",
    "\n",
    "test_transformed[\"Claim\"] = le_claim.transform(test_transformed[\"Claim\"])\n",
    "\n",
    "cols = [c for c in test_transformed.columns if c != \"Claim\"] + [\"Claim\"]\n",
    "test_transformed = test_transformed[cols]\n",
    "\n",
    "print(\"Test data encoded\")\n",
    "print(f\"Test shape before dropping columns: {test_transformed.shape}\")\n",
    "print(f\"Test columns: {list(test_transformed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Drop Same Columns as Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformed = test_transformed.drop(columns=cols_to_drop)\n",
    "test_transformed = test_transformed.reset_index(drop=True)\n",
    "\n",
    "print(f\"Final test shape: {test_transformed.shape}\")\n",
    "print(f\"Final test columns: {list(test_transformed.columns)}\")\n",
    "\n",
    "assert list(train_transformed.columns) == list(test_transformed.columns), \"Column mismatch between train and test!\"\n",
    "print(\"\\nColumn structure verified: MATCH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_transformed.drop('Claim', axis=1)\n",
    "y_train = train_transformed['Claim']\n",
    "\n",
    "X_test = test_transformed.drop('Claim', axis=1)\n",
    "y_test = test_transformed['Claim']\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(f\"\\nTrain target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest target distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Logistic Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('model', LogisticRegression(max_iter=500, class_weight='balanced', solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best F1 score (CV): {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nF1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ROC Curve Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc_calc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {roc_auc_calc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Logistic Regression')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predictions Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred,\n",
    "    'Probability_Claim': y_pred_proba,\n",
    "    'Correct': y_test.values == y_pred\n",
    "})\n",
    "\n",
    "print(\"\\nPrediction Summary:\")\n",
    "print(f\"Total predictions: {len(predictions_df)}\")\n",
    "print(f\"Correct predictions: {predictions_df['Correct'].sum()}\")\n",
    "print(f\"Incorrect predictions: {(~predictions_df['Correct']).sum()}\")\n",
    "print(f\"Accuracy: {predictions_df['Correct'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(predictions_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
